{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m ----------------------------------------------------------------------\n",
      "|                       M2Det Demo Program                             |\n",
      " ----------------------------------------------------------------------\u001b[0m\n",
      "The Anchor info: \n",
      "{'feature_maps': [64, 32, 16, 8, 4, 2], 'min_dim': 512, 'steps': [8, 16, 32, 64, 107, 320], 'min_sizes': [40.96, 76.8, 168.96, 261.12, 353.28, 445.44], 'max_sizes': [76.8, 168.96, 261.12, 353.28, 445.44, 537.6], 'aspect_ratios': [[2, 3], [2, 3], [2, 3], [2, 3], [2, 3], [2, 3]], 'variance': [0.1, 0.2], 'clip': True}\n",
      "\u001b[1m\u001b[33m===> Constructing M2Det model\u001b[0m\n",
      "Loading resume network...\n",
      "\u001b[1m\u001b[33m===> Finished constructing and loading model\u001b[0m\n",
      "Found 3000 test images and we are going to predict them...\n",
      "Progress: 0.0000, Progress: 2.0000, Progress: 4.0000, Progress: 6.0000, Progress: 8.0000, Progress: 10.0000, Progress: 12.0000, Progress: 14.0000, Progress: 16.0000, Progress: 18.0000, Progress: 20.0000, Progress: 22.0000, Progress: 24.0000, Progress: 26.0000, Progress: 28.0000, Progress: 30.0000, Progress: 32.0000, Progress: 34.0000, Progress: 36.0000, Progress: 38.0000, Progress: 40.0000, Progress: 42.0000, Progress: 44.0000, Progress: 46.0000, Progress: 48.0000, Progress: 50.0000, Progress: 52.0000, Progress: 54.0000, Progress: 58.0000, Progress: 60.0000, Progress: 62.0000, Progress: 64.0000, Progress: 66.0000, Progress: 68.0000, Progress: 70.0000, Progress: 72.0000, Progress: 74.0000, Progress: 76.0000, Progress: 78.0000, Progress: 80.0000, Progress: 82.0000, Progress: 84.0000, Progress: 86.0000, Progress: 88.0000, Progress: 90.0000, Progress: 92.0000, Progress: 94.0000, Progress: 96.0000, Progress: 98.0000, ###############################\n",
      "Averaged FPS: 27.76920024771839\n",
      "###############################\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "### import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time,pdb\n",
    "from torch.multiprocessing import Pool\n",
    "from utils.nms_wrapper import nms\n",
    "from utils.timer import Timer\n",
    "from configs.CC import Config\n",
    "import argparse\n",
    "from layers.functions import Detect, PriorBox\n",
    "from m2det import build_net\n",
    "from data import BaseTransform\n",
    "from utils.core import *\n",
    "from utils.pycocotools.coco import COCO\n",
    "\n",
    "print_info(' ----------------------------------------------------------------------\\n'\n",
    "           '|                       M2Det Demo Program                             |\\n'\n",
    "           ' ----------------------------------------------------------------------', ['yellow','bold'])\n",
    "\n",
    "global cfg\n",
    "\n",
    "im_path = \"/home/jess/creDa_test_private_final/JPEGImages/All/\"\n",
    "cam = -1\n",
    "show = False\n",
    "checkpoint_id=43\n",
    "\n",
    "cfg = Config.fromfile(\"configs/m2det512_mobilenetv3.py\")\n",
    "anchor_config = anchors(cfg)\n",
    "print_info('The Anchor info: \\n{}'.format(anchor_config))\n",
    "priorbox = PriorBox(anchor_config)\n",
    "net = build_net('test',\n",
    "                size = cfg.model.input_size,\n",
    "                config = cfg.model.m2det_config)\n",
    "init_net(net, cfg, \"weights/mbv3.pth\")\n",
    "fp = open('m2_mobilenetv3_%d.csv' % (checkpoint_id), 'w')\n",
    "\n",
    "print_info('===> Finished constructing and loading model',['yellow','bold'])\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    priors = priorbox.forward()\n",
    "    if cfg.test_cfg.cuda:\n",
    "        net = net.cuda()\n",
    "        priors = priors.cuda()\n",
    "        cudnn.benchmark = True\n",
    "    else:\n",
    "        net = net.cpu()\n",
    "_preprocess = BaseTransform(cfg.model.input_size, cfg.model.rgb_means, (2, 0, 1))\n",
    "detector = Detect(cfg.model.m2det_config.num_classes, cfg.loss.bkg_label, anchor_config)\n",
    "\n",
    "def _to_color(indx, base):\n",
    "    \"\"\" return (b, r, g) tuple\"\"\"\n",
    "    base2 = base * base\n",
    "    b = 2 - indx / base2\n",
    "    r = 2 - (indx % base2) / base\n",
    "    g = 2 - (indx % base2) % base\n",
    "    return b * 127, r * 127, g * 127\n",
    "base = int(np.ceil(pow(cfg.model.m2det_config.num_classes, 1. / 3)))\n",
    "colors = [_to_color(x, base) for x in range(cfg.model.m2det_config.num_classes)]\n",
    "cats = [_.strip().split(',')[-1] for _ in open('id.txt','r').readlines()]\n",
    "labels = tuple(['__background__'] + cats)\n",
    "\n",
    "def draw_detection(im, bboxes, scores, cls_inds, fps, thr=0.2):\n",
    "    imgcv = np.copy(im)\n",
    "    h, w, _ = imgcv.shape\n",
    "    for i, box in enumerate(bboxes):\n",
    "        if scores[i] < thr:\n",
    "            continue\n",
    "        cls_indx = int(cls_inds[i])\n",
    "        box = [int(_) for _ in box]\n",
    "        thick = int((h + w) / 300)\n",
    "        cv2.rectangle(imgcv,\n",
    "                      (box[0], box[1]), (box[2], box[3]),\n",
    "                      colors[cls_indx], thick)\n",
    "        mess = '%s: %.3f' % (labels[cls_indx], scores[i])\n",
    "        cv2.putText(imgcv, mess, (box[0], box[1] - 7),\n",
    "                    0, 1e-3 * h, colors[cls_indx], thick // 3)\n",
    "        if fps >= 0:\n",
    "            cv2.putText(imgcv, '%.2f' % fps + ' fps', (w - 160, h - 15), 0, 2e-3 * h, (255, 255, 255), thick // 2)\n",
    "\n",
    "    return imgcv\n",
    "\n",
    "im_fnames = sorted((fname for fname in os.listdir(im_path) if os.path.splitext(fname)[-1] == '.jpg'))\n",
    "im_fnames = list(os.path.join(im_path, fname) for fname in im_fnames)\n",
    "len1 = len(im_fnames)\n",
    "cnt=0\n",
    "fpss=0.0\n",
    "fp.write('image_filename,label_id,x,y,w,h,confidence\\n')\n",
    "print('Found %d test images and we are going to predict them...' % (len1))\n",
    "for z in range(len1):\n",
    "    fname=im_fnames[z]\n",
    "    image = cv2.imread(fname, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    loop_start = time.time()\n",
    "    w,h = image.shape[1],image.shape[0]\n",
    "    img = _preprocess(image).unsqueeze(0)\n",
    "    if cfg.test_cfg.cuda:\n",
    "        img = img.cuda()\n",
    "    scale = torch.Tensor([w,h,w,h])\n",
    "    out = net(img)\n",
    "    boxes, scores = detector.forward(out, priors)\n",
    "    boxes = (boxes[0]*scale).cpu().numpy()\n",
    "    scores = scores[0].cpu().numpy()\n",
    "    allboxes = []\n",
    "    for j in range(1, cfg.model.m2det_config.num_classes):\n",
    "        inds = np.where(scores[:,j] > cfg.test_cfg.score_threshold)[0]\n",
    "        if len(inds) == 0:\n",
    "            continue\n",
    "        c_bboxes = boxes[inds]\n",
    "        c_scores = scores[inds, j]\n",
    "        c_dets = np.hstack((c_bboxes, c_scores[:, np.newaxis])).astype(np.float32, copy=False)\n",
    "        soft_nms = cfg.test_cfg.soft_nms\n",
    "#         keep = nms(c_dets, cfg.test_cfg.iou, force_cpu = soft_nms)\n",
    "#         keep = keep[:cfg.test_cfg.keep_per_class]\n",
    "#         c_dets = c_dets[keep, :]\n",
    "        allboxes.extend([_.tolist()+[j] for _ in c_dets])\n",
    "\n",
    "    loop_time = time.time() - loop_start\n",
    "    if allboxes==[]:\n",
    "        continue\n",
    "    allboxes = np.array(allboxes)\n",
    "    boxes = allboxes[:,:4]\n",
    "    scores = allboxes[:,4]\n",
    "    cls_inds = allboxes[:,5]\n",
    "    fp.write(''.join(['{},{},{},{:.3f}\\n'.format( \\\n",
    "            fname.split('/')[-1],int(oo),'%d,%d,%d,%d' % (o[0],o[1],o[2]-o[0],o[3]-o[1]),ooo) for o,oo,ooo in zip(boxes,cls_inds,scores)]))\n",
    "    fps = 1.0 / float(loop_time)\n",
    "    fpss = fpss+fps\n",
    "    im2show = draw_detection(image, boxes, scores, cls_inds, fps)\n",
    "    cv2.imwrite('detected/%s' % (os.path.basename(fname)), im2show)\n",
    "    if z % (len1//50)==0:\n",
    "        print(\"Progress: %.4f\" % (z/len1 * 100.0), end=\", \")\n",
    "print(\"###############################\")\n",
    "print(\"Averaged FPS:\", fpss/len1)\n",
    "print(\"###############################\")\n",
    "fp.close()\n",
    "del net, image, allboxes, boxes, scores, detector\n",
    "torch.cuda.empty_cache() \n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os._exit(00)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
